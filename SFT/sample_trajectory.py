import asyncio
import json
import os
import sys
from typing import Set, Tuple

from deepagents import create_deep_agent
from langchain_openai import ChatOpenAI
from langchain.messages import HumanMessage, AIMessage, ToolMessage
from langchain.agents.middleware import ToolRetryMiddleware

# ===============================
# è·¯å¾„å¤„ç†ï¼ˆä¸ä½ åŸæ¥ä¸€è‡´ï¼‰
# ===============================
current_file = os.path.abspath(__file__)
current_dir = os.path.dirname(current_file)
root_dir = os.path.dirname(current_dir)
sys.path.append(root_dir)

from prompts import MainAgentPrompt
from tools.SubAgentTool import init_subagents

# ===============================
# é…ç½®
# ===============================
PROMPT_FILE = "/Volumes/Samsung/Projects/robotagent/SFT/data.txt"
OUTPUT_JSONL = "trajectories.jsonl"
SAMPLES_PER_PROMPT = 1


# ===============================
# å·¥å…·å‡½æ•°ï¼šåŠ è½½å·²å®Œæˆçš„ (prompt_id, attempt_id)
# ===============================
def load_finished_keys(jsonl_path: str) -> Set[Tuple[int, int]]:
    finished = set()
    if not os.path.exists(jsonl_path):
        return finished

    with open(jsonl_path, "r", encoding="utf-8") as f:
        for line in f:
            if not line.strip():
                continue
            try:
                item = json.loads(line)
                finished.add((item["prompt_id"], item["attempt_id"]))
            except Exception:
                # é˜²æ­¢å•è¡ŒæŸåå¯¼è‡´æ•´ä½“å¤±è´¥
                continue
    return finished


# ===============================
# æ ¸å¿ƒï¼šå¢é‡å¼é‡‡æ ·ï¼ˆå¯æ–­ç‚¹é‡å¯ï¼‰
# ===============================
async def sample_trajectories_incremental(
    agent,
    prompts,
    samples_per_prompt: int,
    output_path: str,
):
    finished_keys = load_finished_keys(output_path)

    print(f"ğŸ” å·²æ£€æµ‹åˆ°å®Œæˆçš„ trajectory æ•°é‡: {len(finished_keys)}")

    for prompt_id, prompt in enumerate(prompts):
        print(f"\nğŸ“Œ Prompt {prompt_id}: {prompt.strip()}")

        for attempt_id in range(samples_per_prompt):
            key = (prompt_id, attempt_id)

            if key in finished_keys:
                print(f"â­ è·³è¿‡ Prompt {prompt_id} Attempt {attempt_id}")
                continue

            print(f"â–¶ è¿è¡Œ Prompt {prompt_id} Attempt {attempt_id}")

            try:
                response = await agent.ainvoke(
                    {"messages": [{"role": "user", "content": prompt}]}
                )
            except Exception as e:
                print(f"âŒ è°ƒç”¨å¤±è´¥ï¼Œè·³è¿‡è¯¥æ ·æœ¬: {e}")
                continue

            messages = []

            for msg in response["messages"]:
                if isinstance(msg, (HumanMessage, AIMessage, ToolMessage)):
                    if isinstance(msg, HumanMessage):
                        role = "user"
                    elif isinstance(msg, AIMessage):
                        role = "assistant"
                    else:
                        role = "tool"

                    item = {
                        "role": role,
                        "content": msg.content,
                    }

                    if isinstance(msg, ToolMessage):
                        if msg.name:
                            item["name"] = msg.name
                        if msg.tool_call_id:
                            item["tool_call_id"] = msg.tool_call_id

                    messages.append(item)

            record = {
                "prompt_id": prompt_id,
                "attempt_id": attempt_id,
                "messages": messages,
            }

            # âœ… ç«‹åˆ»è¿½åŠ å†™å…¥ï¼ˆåŸå­æ€§å¼ºï¼‰
            with open(output_path, "a", encoding="utf-8") as f:
                f.write(json.dumps(record, ensure_ascii=False) + "\n")

            finished_keys.add(key)
            print(f"âœ… å·²ä¿å­˜ Prompt {prompt_id} Attempt {attempt_id}")


# ===============================
# ä¸»å…¥å£
# ===============================
async def main():
    # åˆå§‹åŒ– subagents
    subagents = list(await init_subagents())

    # åˆå§‹åŒ– LLM
    chat = ChatOpenAI(
        base_url="http://localhost:1234/v1",
        model="qwen-qwen3-14b-mlx@4bit",
        api_key="no_need",
    )

    # åˆ›å»º Deep Agent
    agent = create_deep_agent(
        model=chat,
        tools=[],
        system_prompt=MainAgentPrompt.SYSTEM_PROMPT,
        subagents=subagents,
        middleware=[
            ToolRetryMiddleware(
                max_retries=3,
                backoff_factor=2.0,
                initial_delay=1.0,
            )
        ],
    )

    # è¯»å– prompts
    with open(PROMPT_FILE, "r", encoding="utf-8") as f:
        prompts = [line.strip() for line in f if line.strip()]

    print(f"ğŸ“„ åŠ è½½ prompt æ•°é‡: {len(prompts)}")

    await sample_trajectories_incremental(
        agent=agent,
        prompts=prompts,
        samples_per_prompt=SAMPLES_PER_PROMPT,
        output_path=OUTPUT_JSONL,
    )

    print("\nğŸ‰ é‡‡æ ·å®Œæˆï¼ˆæˆ–å·²å…¨éƒ¨å®Œæˆï¼‰")


if __name__ == "__main__":
    asyncio.run(main())
